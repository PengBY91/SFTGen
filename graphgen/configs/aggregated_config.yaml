read:
  input_file: resources/input_examples/jsonl_demo.jsonl # input file path, support json, jsonl, txt, pdf. See resources/input_examples for examples
split:
  chunk_size: 1024 # chunk size for text splitting
  chunk_overlap: 100 # chunk overlap for text splitting
  # 批量请求优化参数
  enable_batch_requests: true
  batch_size: 30
  max_wait_time: 1.0
  use_adaptive_batching: true
  min_batch_size: 10
  max_batch_size: 50
  enable_extraction_cache: true
  # Prompt合并优化
  enable_prompt_merging: true
  prompt_merge_size: 5
search: # web search configuration
  enabled: false # whether to enable web search
  search_types: ["google"] # search engine types, support: google, bing, uniprot, wikipedia
quiz_and_judge: # quiz and test whether the LLM masters the knowledge points
  enabled: true
  quiz_samples: 2 # number of quiz samples to generate
  re_judge: false # whether to re-judge the existing quiz samples
  enable_batch_requests: true
  batch_size: 30
  max_wait_time: 1.0
partition: # graph partition configuration
  method: ece # ece is a custom partition method based on comprehension loss
  method_params:
    max_units_per_community: 20 # max nodes and edges per community
    min_units_per_community: 5 # min nodes and edges per community
    max_tokens_per_community: 10240 # max tokens per community
    unit_sampling: max_loss # unit sampling strategy, support: random, max_loss, min_loss
generate:
  mode: aggregated # atomic, aggregated, multi_hop, cot
  data_format: ChatML # Alpaca, Sharegpt, ChatML
  # 批量请求优化
  enable_batch_requests: true
  batch_size: 30
  max_wait_time: 1.0
  use_adaptive_batching: true
  min_batch_size: 10
  max_batch_size: 50
  # 缓存优化
  enable_prompt_cache: true
  cache_max_size: 50000
  cache_ttl: null
  # 合并模式优化（减少50%调用）
  use_combined_mode: true
  # 去重优化
  enable_deduplication: true
  persistent_deduplication: true
