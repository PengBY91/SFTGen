# å¤§æ¨¡å‹è°ƒç”¨åˆ†æä¸ä¼˜åŒ–æ–¹æ¡ˆ

## ğŸ“Š æ•´ä½“æµç¨‹ä¸­çš„LLMè°ƒç”¨

### 1. å›¾è°±æŠ½å–é˜¶æ®µï¼ˆKnowledge Graph Extractionï¼‰

#### è°ƒç”¨ç‚¹åˆ†æ

**æ–‡ä»¶**: `graphgen/operators/build_kg/build_text_kg.py` å’Œ `build_mm_kg.py`

```
æ–‡æœ¬å¤„ç†æµç¨‹:
1. è¯»å–æ–‡æ¡£ â†’ 2. åˆ†å— â†’ 3. KGæŠ½å– â†’ 4. èŠ‚ç‚¹åˆå¹¶ â†’ 5. è¾¹åˆå¹¶
                              â†“ LLMè°ƒç”¨
                        æ¯ä¸ªchunkä¸€æ¬¡LLMè°ƒç”¨
```

**å…³é”®ä»£ç **:
```python
kg_builder = LightRAGKGBuilder(
    llm_client=llm_client,
    enable_batch_requests=True,      # é»˜è®¤å¯ç”¨
    batch_size=10,                    # é»˜è®¤æ‰¹é‡å¤§å°
    max_wait_time=0.5,               # æœ€å¤§ç­‰å¾…æ—¶é—´
)

# å¹¶å‘å¤„ç†æ‰€æœ‰chunks
results = await run_concurrent(
    kg_builder.extract,
    chunks,  # Nä¸ªchunks
    desc="[2/4]Extracting entities and relationships",
)
```

**LLMè°ƒç”¨æ¬¡æ•°**: 
- åŸºç¡€è°ƒç”¨: **Nä¸ªchunks = Næ¬¡LLMè°ƒç”¨**
- å¦‚æœå¯ç”¨iterative refinement (å½“å‰æ³¨é‡Šæ‰): **N Ã— (1 + max_loop) æ¬¡è°ƒç”¨**

#### èŠ‚ç‚¹/è¾¹åˆå¹¶é˜¶æ®µ

**æ–‡ä»¶**: `graphgen/models/kg_builder/light_rag_kg_builder.py`

```python
async def merge_nodes(node_data, kg_instance):
    # 1. å®ä½“æ¶ˆæ­§ (deduplication)
    # 2. æè¿°åˆå¹¶ (summarization) - éœ€è¦LLMè°ƒç”¨
    if len(existing_descriptions) > 1 and len(existing_descriptions) <= 10:
        # LLMè°ƒç”¨ï¼šåˆå¹¶æè¿°
        summary_prompt = KG_SUMMARIZATION_PROMPT[language].format(...)
        if self.batch_manager:
            summary = await self.batch_manager.add_request(summary_prompt)
```

**LLMè°ƒç”¨æ¬¡æ•°**:
- **Mä¸ªéœ€è¦åˆå¹¶çš„èŠ‚ç‚¹ = Mæ¬¡LLMè°ƒç”¨** (Mé€šå¸¸ << N)

---

### 2. é—®ç­”å¯¹ç”Ÿæˆé˜¶æ®µï¼ˆQA Generationï¼‰

#### è°ƒç”¨ç‚¹åˆ†æ

**æ–‡ä»¶**: `graphgen/operators/generate/generate_qas.py`

ä¸åŒæ¨¡å¼çš„LLMè°ƒç”¨æ¬¡æ•°ï¼š

| æ¨¡å¼ | é˜¶æ®µ | LLMè°ƒç”¨æ¬¡æ•° | è¯´æ˜ |
|------|------|------------|------|
| **Atomic (å•é˜¶æ®µ)** | é—®é¢˜+ç­”æ¡ˆç”Ÿæˆ | Kæ¬¡ | K = batchæ•°é‡ |
| **Atomic (ä¸¤é˜¶æ®µ)** | 1. é—®é¢˜ç”Ÿæˆ<br>2. ç­”æ¡ˆç”Ÿæˆ | K + Qæ¬¡ | Q = ç”Ÿæˆçš„é—®é¢˜æ•° |
| **Aggregated (åŸå§‹)** | 1. é‡è¿°æ–‡æœ¬<br>2. é—®é¢˜ç”Ÿæˆ | K + K = 2Kæ¬¡ | ä¸¤æ¬¡ç‹¬ç«‹è°ƒç”¨ |
| **Aggregated (åˆå¹¶)** | é‡è¿°+é—®é¢˜ | Kæ¬¡ | å‡å°‘50%è°ƒç”¨ |
| **Multi-hop** | é—®é¢˜+ç­”æ¡ˆ+è·¯å¾„ | Kæ¬¡ | ä¸€æ¬¡ç”Ÿæˆå…¨éƒ¨ |
| **CoT (åŸå§‹)** | 1. æ¨¡æ¿è®¾è®¡<br>2. ç­”æ¡ˆç”Ÿæˆ | K + K = 2Kæ¬¡ | ä¸¤æ¬¡ç‹¬ç«‹è°ƒç”¨ |
| **CoT (åˆå¹¶)** | æ¨¡æ¿+ç­”æ¡ˆ | Kæ¬¡ | å‡å°‘50%è°ƒç”¨ |
| **Allæ¨¡å¼** | æ‰€æœ‰æ¨¡å¼å¹¶å‘ | 4Kæ¬¡ | å››ç§æ¨¡å¼ç‹¬ç«‹ç”Ÿæˆ |

**å…³é”®ä¼˜åŒ–ç‚¹**:
1. **åˆå¹¶æ¨¡å¼** (`use_combined_mode`): Aggregatedå’ŒCoTå¯ä»¥ä¸€æ¬¡ç”Ÿæˆå¤šä¸ªå­—æ®µ
2. **æ‰¹é‡å¤„ç†** (`enable_batch_requests`): å¤šä¸ªbatchå¹¶å‘å¤„ç†
3. **Promptç¼“å­˜** (`enable_prompt_cache`): é¿å…é‡å¤ç›¸åŒçš„promptè°ƒç”¨

---

## ğŸ¯ å½“å‰å·²å®ç°çš„ä¼˜åŒ–

### 1. æ‰¹é‡è¯·æ±‚ç®¡ç†å™¨ (BatchRequestManager)

**æ–‡ä»¶**: `graphgen/utils/batch_request_manager.py`

**å·¥ä½œåŸç†**:
```
è¯·æ±‚1 â”€â”€â”
è¯·æ±‚2 â”€â”€â”¤
è¯·æ±‚3 â”€â”€â”¼â”€â”€> æ”¶é›†åˆ°batch_sizeä¸ª â”€â”€> å¹¶å‘å‘é€ â”€â”€> åˆ†å‘ç»“æœ
...     â”‚    æˆ–ç­‰å¾…max_wait_time
è¯·æ±‚N â”€â”€â”˜
```

**é…ç½®å‚æ•°**:
- `batch_size`: 10 (é»˜è®¤) - æ¯æ‰¹å¤„ç†çš„è¯·æ±‚æ•°
- `max_wait_time`: 0.5ç§’ (é»˜è®¤) - æœ€å¤§ç­‰å¾…æ—¶é—´
- `enable_batching`: True (é»˜è®¤)

**æ•ˆæœ**:
- âœ… å‡å°‘ç½‘ç»œå¾€è¿”æ¬¡æ•°
- âœ… æé«˜å¹¶å‘å¤„ç†æ•ˆç‡
- âš ï¸ å•ä¸ªæ‰¹æ¬¡å†…éƒ¨ä»ç„¶æ˜¯å¤šæ¬¡ç‹¬ç«‹APIè°ƒç”¨

### 2. è‡ªé€‚åº”æ‰¹é‡ç®¡ç†å™¨ (AdaptiveBatchRequestManager)

**æ–‡ä»¶**: `graphgen/utils/adaptive_batch_manager.py`

**ç‰¹æ€§**:
- æ ¹æ®APIå“åº”æ—¶é—´åŠ¨æ€è°ƒæ•´æ‰¹é‡å¤§å°
- æ ¹æ®é”™è¯¯ç‡è‡ªåŠ¨é™ä½æ‰¹é‡
- `min_batch_size`: 5, `max_batch_size`: 50

### 3. Promptç¼“å­˜ (PromptCache)

**æ–‡ä»¶**: `graphgen/utils/prompt_cache.py`

**ä½œç”¨**:
- LRUç¼“å­˜ï¼Œé¿å…é‡å¤ç›¸åŒpromptçš„è°ƒç”¨
- `cache_max_size`: 10000æ¡
- `cache_ttl`: å¯é…ç½®è¿‡æœŸæ—¶é—´

### 4. åˆå¹¶æ¨¡å¼ (Combined Mode)

**ä½ç½®**: Aggregatedå’ŒCoTç”Ÿæˆå™¨

**æ•ˆæœ**:
- Aggregated: 2æ¬¡è°ƒç”¨ â†’ 1æ¬¡è°ƒç”¨ (å‡å°‘50%)
- CoT: 2æ¬¡è°ƒç”¨ â†’ 1æ¬¡è°ƒç”¨ (å‡å°‘50%)

### 5. æŠ½å–ç»“æœç¼“å­˜

**æ–‡ä»¶**: `graphgen/graphgen.py`

**ä½œç”¨**:
- ç¼“å­˜chunkçš„æŠ½å–ç»“æœ
- é¿å…é‡å¤æŠ½å–ç›¸åŒå†…å®¹çš„chunk

---

## ğŸ’¡ å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–çš„ç‚¹

### âŒ å½“å‰é™åˆ¶

**é‡è¦å‘ç°**: 
å½“å‰çš„ `BatchRequestManager` **ä¸æ˜¯çœŸæ­£çš„æ‰¹é‡è°ƒç”¨**ï¼

æŸ¥çœ‹ä»£ç ï¼š
```python:graphgen/utils/batch_request_manager.py
async def _process_batch(self):
    # å–å‡ºå½“å‰æ‰¹æ¬¡
    batch = self.request_queue[:self.batch_size]
    
    # å¹¶å‘å¤„ç†æ‰¹æ¬¡ä¸­çš„è¯·æ±‚ï¼ˆä½†æ¯ä¸ªè¯·æ±‚ä»æ˜¯ç‹¬ç«‹è°ƒç”¨ï¼‰
    tasks = []
    for request in batch:
        task = self._process_single_request(request)
        tasks.append(task)
    
    # ç­‰å¾…æ‰€æœ‰è¯·æ±‚å®Œæˆ
    await asyncio.gather(*tasks)
```

**é—®é¢˜**: æ¯ä¸ªrequestä»ç„¶è°ƒç”¨ä¸€æ¬¡ `llm_client.generate_answer()`

### âœ… ä¼˜åŒ–æ–¹æ¡ˆ

#### æ–¹æ¡ˆ1: çœŸæ­£çš„æ‰¹é‡APIè°ƒç”¨ â­â­â­â­â­

**é€‚ç”¨åœºæ™¯**: APIæ”¯æŒæ‰¹é‡è¯·æ±‚ï¼ˆå¦‚OpenAI Batch APIï¼‰

**å®ç°æ€è·¯**:
```python
# ä¼ªä»£ç 
async def process_batch_with_real_batching(requests):
    # å°†å¤šä¸ªpromptåˆå¹¶æˆä¸€ä¸ªæ‰¹é‡è¯·æ±‚
    batch_payload = {
        "requests": [
            {"id": i, "prompt": req.prompt}
            for i, req in enumerate(requests)
        ]
    }
    
    # ä¸€æ¬¡APIè°ƒç”¨å¤„ç†å¤šä¸ªè¯·æ±‚
    batch_response = await llm_client.batch_generate(batch_payload)
    
    # åˆ†å‘ç»“æœ
    for i, response in enumerate(batch_response["responses"]):
        set_result(requests[i].index, response["text"])
```

**ä¼˜ç‚¹**:
- âœ… çœŸæ­£å‡å°‘APIè°ƒç”¨æ¬¡æ•°
- âœ… é™ä½APIè´¹ç”¨ï¼ˆæŸäº›APIæ‰¹é‡è°ƒç”¨æœ‰æŠ˜æ‰£ï¼‰
- âœ… å‡å°‘ç½‘ç»œå¼€é”€

**ç¼ºç‚¹**:
- âš ï¸ éœ€è¦APIæ”¯æŒæ‰¹é‡æ¨¡å¼
- âš ï¸ å¯èƒ½å¢åŠ å•æ¬¡è¯·æ±‚å»¶è¿Ÿ

**é¢„è®¡æ•ˆæœ**:
- **è°ƒç”¨æ¬¡æ•°**: Næ¬¡ â†’ N/batch_sizeæ¬¡
- **è´¹ç”¨**: å¯èƒ½å‡å°‘10-30%ï¼ˆå–å†³äºAPIå®šä»·ï¼‰

---

#### æ–¹æ¡ˆ2: å¢å¤§batch_sizeå’Œå¹¶å‘æ•° â­â­â­â­

**é…ç½®æ–‡ä»¶è°ƒæ•´**:

```yaml
# å½“å‰é»˜è®¤å€¼
split_config:
  enable_batch_requests: true
  batch_size: 10              # å¯ä»¥å¢å¤§åˆ° 20-50
  max_wait_time: 0.5          # å¯ä»¥å¢å¤§åˆ° 1.0-2.0
  
generation_config:
  enable_batch_requests: true
  batch_size: 10              # å¯ä»¥å¢å¤§åˆ° 20-50
  max_wait_time: 0.5          # å¯ä»¥å¢å¤§åˆ° 1.0-2.0
```

**å»ºè®®è°ƒæ•´**:
```yaml
# ä¼˜åŒ–å
split_config:
  batch_size: 30              # å¢å¤§3å€
  max_wait_time: 1.0          # å¢å¤§ç­‰å¾…æ—¶é—´ï¼Œæ”¶é›†æ›´å¤šè¯·æ±‚
  use_adaptive_batching: true # å¯ç”¨è‡ªé€‚åº”
  max_batch_size: 50          # è‡ªé€‚åº”ä¸Šé™
  
generation_config:
  batch_size: 30
  max_wait_time: 1.0
  use_adaptive_batching: true
  max_batch_size: 50
```

**æ•ˆæœ**:
- âœ… æé«˜å¹¶å‘å¤„ç†æ•ˆç‡
- âœ… æ›´å¥½åœ°åˆ©ç”¨APIå¹¶å‘é™åˆ¶
- âš ï¸ å¯èƒ½å¢åŠ å†…å­˜ä½¿ç”¨

**é¢„è®¡æå‡**:
- **ååé‡**: æå‡ 2-3å€
- **æ€»è€—æ—¶**: å‡å°‘ 30-50%

---

#### æ–¹æ¡ˆ3: Promptåˆå¹¶ â­â­â­

**æ€è·¯**: å°†å¤šä¸ªå°çš„KGæŠ½å–ä»»åŠ¡åˆå¹¶æˆä¸€ä¸ªå¤§çš„prompt

**ç¤ºä¾‹**:
```python
# å½“å‰: æ¯ä¸ªchunkä¸€æ¬¡è°ƒç”¨
for chunk in chunks:
    prompt = f"Extract entities from: {chunk.content}"
    result = await llm_client.generate(prompt)

# ä¼˜åŒ–å: åˆå¹¶å¤šä¸ªchunks
combined_prompt = """
Extract entities from the following texts:

Text 1:
{chunk1.content}

Text 2:
{chunk2.content}

Text 3:
{chunk3.content}

...
"""
result = await llm_client.generate(combined_prompt)
```

**ä¼˜ç‚¹**:
- âœ… æ˜¾è‘—å‡å°‘APIè°ƒç”¨æ¬¡æ•°
- âœ… é™ä½APIè´¹ç”¨

**ç¼ºç‚¹**:
- âš ï¸ å¯èƒ½è¶…è¿‡tokené™åˆ¶
- âš ï¸ éœ€è¦æ›´å¤æ‚çš„å“åº”è§£æ
- âš ï¸ é”™è¯¯ä¼ æ’­ï¼ˆä¸€ä¸ªchunkå¤±è´¥å¯èƒ½å½±å“æ•´æ‰¹ï¼‰

**é¢„è®¡æ•ˆæœ**:
- **è°ƒç”¨æ¬¡æ•°**: Næ¬¡ â†’ N/merge_factoræ¬¡
- å¦‚æœmerge_factor=5: **å‡å°‘80%è°ƒç”¨**

---

#### æ–¹æ¡ˆ4: å¯ç”¨æ›´å¤šç¼“å­˜ â­â­â­â­

**å½“å‰çŠ¶æ€**:
```python
# å·²å¯ç”¨
enable_extraction_cache: true  # æŠ½å–ç»“æœç¼“å­˜
enable_prompt_cache: true       # Promptç¼“å­˜
```

**é¢å¤–ä¼˜åŒ–**:
1. **å¢å¤§ç¼“å­˜å¤§å°**:
```python
cache_max_size: 10000  # é»˜è®¤
# æ”¹ä¸º
cache_max_size: 50000  # 5å€å®¹é‡
```

2. **æŒä¹…åŒ–ç¼“å­˜** (å½“å‰æ˜¯å†…å­˜ç¼“å­˜):
```python
# å°†ç¼“å­˜æŒä¹…åŒ–åˆ°ç£ç›˜
cache_storage = JsonKVStorage(working_dir, namespace="llm_cache")
```

3. **è·¨ä¼šè¯ç¼“å­˜**:
```python
# ä¸åŒä»»åŠ¡ä¹‹é—´å…±äº«ç¼“å­˜
cache_ttl: null  # æ°¸ä¸è¿‡æœŸ
# æˆ–è®¾ç½®è¾ƒé•¿çš„è¿‡æœŸæ—¶é—´
cache_ttl: 86400  # 24å°æ—¶
```

**æ•ˆæœ**:
- âœ… é‡å¤æ–‡æ¡£é›¶é¢å¤–è°ƒç”¨
- âœ… ç›¸ä¼¼å†…å®¹å‘½ä¸­ç‡æå‡

---

#### æ–¹æ¡ˆ5: å¹¶å‘æ§åˆ¶ä¼˜åŒ– â­â­â­

**å½“å‰**: `run_concurrent` ä½¿ç”¨é»˜è®¤å¹¶å‘è®¾ç½®

**ä¼˜åŒ–**:
```python
# å½“å‰
results = await run_concurrent(
    kg_builder.extract,
    chunks,
    desc="[2/4]Extracting entities",
)

# ä¼˜åŒ–åï¼šå¢åŠ å¹¶å‘æ•°
from asyncio import Semaphore

async def run_concurrent_with_limit(coro_fn, items, max_concurrent=50):
    semaphore = Semaphore(max_concurrent)
    
    async def limited_coro(item):
        async with semaphore:
            return await coro_fn(item)
    
    tasks = [limited_coro(item) for item in items]
    return await asyncio.gather(*tasks)

# ä½¿ç”¨
results = await run_concurrent_with_limit(
    kg_builder.extract,
    chunks,
    max_concurrent=50,  # å¢åŠ å¹¶å‘æ•°
)
```

**æ•ˆæœ**:
- âœ… æ›´å¥½åœ°åˆ©ç”¨APIå¹¶å‘é™åˆ¶
- âœ… æ˜¾è‘—å‡å°‘æ€»è€—æ—¶

---

## ğŸ“ˆ ç»¼åˆä¼˜åŒ–å»ºè®®

### ç«‹å³å¯å®æ–½ï¼ˆæ— éœ€ä»£ç ä¿®æ”¹ï¼‰

1. **è°ƒæ•´é…ç½®å‚æ•°**:
```yaml
# graphgen/configs/*.yaml
split_config:
  batch_size: 30                     # ä»10å¢å¤§åˆ°30
  max_wait_time: 1.0                 # ä»0.5å¢å¤§åˆ°1.0
  use_adaptive_batching: true        # å¯ç”¨è‡ªé€‚åº”
  max_batch_size: 50
  
generation_config:
  batch_size: 30
  max_wait_time: 1.0
  use_adaptive_batching: true
  max_batch_size: 50
  enable_prompt_cache: true
  cache_max_size: 50000              # å¢å¤§ç¼“å­˜
```

**é¢„è®¡æ•ˆæœ**: 
- è°ƒç”¨æ•ˆç‡æå‡ **2-3å€**
- æ€»è€—æ—¶å‡å°‘ **30-50%**

---

### ä¸­æœŸä¼˜åŒ–ï¼ˆéœ€è¦å°‘é‡ä»£ç ä¿®æ”¹ï¼‰

2. **ä½¿ç”¨åˆå¹¶æ¨¡å¼**:
```python
# åœ¨generation_configä¸­å¯ç”¨
use_combined_mode: true  # Aggregatedå’ŒCoTå‡å°‘50%è°ƒç”¨
```

3. **å¢å¤§å¹¶å‘æ•°**:
```python
# ä¿®æ”¹run_concurrentï¼Œå¢åŠ max_concurrentå‚æ•°
max_concurrent: 50  # é»˜è®¤æ˜¯æ— é™åˆ¶
```

**é¢„è®¡æ•ˆæœ**:
- é¢å¤–å‡å°‘ **20-30%è°ƒç”¨**
- ååé‡æå‡ **50-100%**

---

### é•¿æœŸä¼˜åŒ–ï¼ˆéœ€è¦è¾ƒå¤§æ”¹åŠ¨ï¼‰

4. **å®ç°çœŸæ­£çš„æ‰¹é‡APIè°ƒç”¨**:
- éœ€è¦æ ¹æ®ä½¿ç”¨çš„APIæä¾›å•†å®ç°æ‰¹é‡æ¥å£
- OpenAI: ä½¿ç”¨ Batch API
- å…¶ä»–: å®ç°è‡ªå®šä¹‰æ‰¹é‡åè®®

5. **Promptåˆå¹¶ç­–ç•¥**:
- å°†å¤šä¸ªå°chunkåˆå¹¶æˆä¸€ä¸ªå¤§prompt
- éœ€è¦å®ç°æ™ºèƒ½åˆ†ç»„å’Œå“åº”è§£æ

**é¢„è®¡æ•ˆæœ**:
- è°ƒç”¨æ¬¡æ•°å‡å°‘ **70-80%**
- APIè´¹ç”¨å‡å°‘ **50-70%**

---

## ğŸ“Š ä¼˜åŒ–æ•ˆæœé¢„æµ‹

å‡è®¾å½“å‰åœºæ™¯ï¼š
- 100ä¸ªæ–‡æ¡£
- æ¯ä¸ªæ–‡æ¡£åˆ†æˆ10ä¸ªchunks
- æ€»å…±1000ä¸ªchunks
- ç”Ÿæˆ500ä¸ªQAå¯¹

### å½“å‰çŠ¶æ€

| é˜¶æ®µ | è°ƒç”¨æ¬¡æ•° | è¯´æ˜ |
|------|---------|------|
| KGæŠ½å– | 1000æ¬¡ | æ¯ä¸ªchunkä¸€æ¬¡ |
| èŠ‚ç‚¹åˆå¹¶ | ~50æ¬¡ | éƒ¨åˆ†èŠ‚ç‚¹éœ€è¦åˆå¹¶ |
| QAç”Ÿæˆ (Atomic) | 100æ¬¡ | å‡è®¾100ä¸ªbatch |
| **æ€»è®¡** | **~1150æ¬¡** | |

### ä¼˜åŒ–åï¼ˆç«‹å³å¯å®æ–½ï¼‰

| é˜¶æ®µ | è°ƒç”¨æ¬¡æ•° | ä¼˜åŒ–æ–¹æ³• | å‡å°‘æ¯”ä¾‹ |
|------|---------|---------|---------|
| KGæŠ½å– | 1000æ¬¡ â†’ 1000æ¬¡ | å¹¶å‘ä¼˜åŒ–ï¼Œä¸å‡å°‘è°ƒç”¨æ¬¡æ•° | 0% |
| èŠ‚ç‚¹åˆå¹¶ | 50æ¬¡ â†’ 50æ¬¡ | å·²ç»æ˜¯æ‰¹é‡ | 0% |
| QAç”Ÿæˆ | 100æ¬¡ â†’ 100æ¬¡ | å·²ç»æ˜¯æ‰¹é‡ | 0% |
| **æ€»è€—æ—¶** | **100%** â†’ **40-50%** | æ‰¹é‡å¤§å°å¢å¤§+å¹¶å‘å¢åŠ  | **å‡å°‘50-60%** |

### ä¼˜åŒ–åï¼ˆé•¿æœŸï¼‰

| é˜¶æ®µ | è°ƒç”¨æ¬¡æ•° | ä¼˜åŒ–æ–¹æ³• | å‡å°‘æ¯”ä¾‹ |
|------|---------|---------|---------|
| KGæŠ½å– | 1000æ¬¡ â†’ 200æ¬¡ | Promptåˆå¹¶(5åˆ1) | 80% |
| èŠ‚ç‚¹åˆå¹¶ | 50æ¬¡ â†’ 50æ¬¡ | ä¸å˜ | 0% |
| QAç”Ÿæˆ | 100æ¬¡ â†’ 20æ¬¡ | çœŸæ­£æ‰¹é‡API(batch=5) | 80% |
| **æ€»è®¡** | **1150æ¬¡** â†’ **270æ¬¡** | | **å‡å°‘76%** |

---

## ğŸš€ å®æ–½å»ºè®®

### é˜¶æ®µ1ï¼šç«‹å³ä¼˜åŒ–ï¼ˆ1å¤©ï¼‰

1. ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œå¢å¤§batch_sizeå’Œmax_wait_time
2. å¯ç”¨use_adaptive_batching
3. å¢å¤§cache_max_size

### é˜¶æ®µ2ï¼šä¸­æœŸä¼˜åŒ–ï¼ˆ3-5å¤©ï¼‰

1. ä¿®æ”¹run_concurrentï¼Œå¢åŠ å¹¶å‘æ§åˆ¶å‚æ•°
2. å…¨é¢å¯ç”¨use_combined_mode
3. å®ç°æŒä¹…åŒ–ç¼“å­˜

### é˜¶æ®µ3ï¼šé•¿æœŸä¼˜åŒ–ï¼ˆ1-2å‘¨ï¼‰

1. ç ”ç©¶APIçš„æ‰¹é‡è°ƒç”¨æ¥å£
2. å®ç°çœŸæ­£çš„æ‰¹é‡APIè°ƒç”¨
3. å®ç°Promptåˆå¹¶ç­–ç•¥
4. æ€§èƒ½æµ‹è¯•å’Œè°ƒä¼˜

---

## ğŸ“ æ€»ç»“

1. **å½“å‰çš„BatchRequestManageræ˜¯ä¼ªæ‰¹é‡**ï¼Œåªæ˜¯å¹¶å‘å¤„ç†ï¼Œä¸æ˜¯çœŸæ­£å‡å°‘è°ƒç”¨æ¬¡æ•°
2. **ç«‹å³å¯å®æ–½çš„ä¼˜åŒ–**ä¸»è¦æ˜¯æé«˜å¹¶å‘å’Œååé‡ï¼Œä¸ç›´æ¥å‡å°‘è°ƒç”¨æ¬¡æ•°
3. **çœŸæ­£å‡å°‘è°ƒç”¨æ¬¡æ•°**éœ€è¦å®ç°æ‰¹é‡APIæˆ–Promptåˆå¹¶
4. **æœ€å¤§ä¼˜åŒ–æ½œåŠ›**: å‡å°‘ 70-80%çš„LLMè°ƒç”¨æ¬¡æ•°å’Œ50-70%çš„APIè´¹ç”¨

