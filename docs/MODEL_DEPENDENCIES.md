# æ¨¡å‹ä¾èµ–å’Œç½‘ç»œéœ€æ±‚

æœ¬æ–‡æ¡£åˆ—å‡ºé¡¹ç›®ä¸­æ‰€æœ‰éœ€è¦ä»ç½‘ç»œä¸‹è½½çš„æ¨¡å‹å’Œæ•°æ®ï¼Œä»¥åŠå¦‚ä½•é…ç½®æœ¬åœ°å­˜å‚¨ã€‚

## ğŸ“‹ ä¾èµ–æ¸…å•

### 1. âœ… Tiktoken æ¨¡å‹ï¼ˆå·²é…ç½®æœ¬åœ°å­˜å‚¨ï¼‰

- **æ¨¡å‹**: `cl100k_base`
- **ä½ç½®**: `models/tokenizer/`
- **çŠ¶æ€**: âœ… å·²é…ç½®ä¸ºæœ¬åœ°å­˜å‚¨
- **è¯¦æƒ…**: å‚è§ [TOKENIZER_LOCAL_STORAGE.md](TOKENIZER_LOCAL_STORAGE.md)

### 2. âœ… HuggingFace Transformers æ¨¡å‹ï¼ˆå·²é…ç½®æœ¬åœ°å­˜å‚¨ï¼‰

#### 2.1 Tokenizerï¼ˆå¤‡ç”¨ï¼‰

- **æ–‡ä»¶**: `graphgen/models/tokenizer/__init__.py`
- **è§¦å‘æ¡ä»¶**: å½“ `tokenizer_name` ä¸æ˜¯ tiktoken æ”¯æŒçš„ç¼–ç æ—¶
- **æ¨¡å‹**: æ ¹æ® `tokenizer_name` å‚æ•°åŠ¨æ€ä¸‹è½½
- **ä»£ç ä½ç½®**: ç¬¬27è¡Œ `AutoTokenizer.from_pretrained(tokenizer_name, cache_dir=...)`
- **ä½¿ç”¨åœºæ™¯**: å¦‚æœç”¨æˆ·æŒ‡å®šäº†é tiktoken çš„ tokenizerï¼ˆå¦‚ HuggingFace æ¨¡å‹åï¼‰
- **çŠ¶æ€**: âœ… å·²é…ç½®ä¸ºæœ¬åœ°å­˜å‚¨åˆ° `models/huggingface/`

#### 2.2 Reward Evaluator æ¨¡å‹

- **æ–‡ä»¶**: `graphgen/models/evaluator/reward_evaluator.py`
- **æ¨¡å‹**: `OpenAssistant/reward-model-deberta-v3-large-v2`
- **ç”¨é€”**: ç”¨äºè¯„ä¼°ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡ï¼ˆå¥–åŠ±æ¨¡å‹ï¼‰
- **ä»£ç ä½ç½®**: ç¬¬32-33è¡Œ
- **ä½¿ç”¨åœºæ™¯**: è¿è¡Œè¯„ä¼°è„šæœ¬ `graphgen/evaluate.py` æ—¶
- **å¤§å°**: çº¦ 1-2 GB
- **çŠ¶æ€**: âœ… å·²é…ç½®ä¸ºæœ¬åœ°å­˜å‚¨åˆ° `models/huggingface/`

#### 2.3 UniEval æ¨¡å‹

- **æ–‡ä»¶**: `graphgen/models/evaluator/uni_evaluator.py`
- **æ¨¡å‹**: `MingZhong/unieval-sum`
- **ç”¨é€”**: ç”¨äºè¯„ä¼°æ–‡æœ¬çš„è‡ªç„¶æ€§ã€è¿è´¯æ€§å’Œç†è§£æ€§
- **ä»£ç ä½ç½®**: ç¬¬58-59è¡Œ
- **ä½¿ç”¨åœºæ™¯**: è¿è¡Œè¯„ä¼°è„šæœ¬ `graphgen/evaluate.py` æ—¶
- **å¤§å°**: çº¦ 1-2 GB
- **çŠ¶æ€**: âœ… å·²é…ç½®ä¸ºæœ¬åœ°å­˜å‚¨åˆ° `models/huggingface/`

### 3. âœ… NLTK æ•°æ®ï¼ˆå·²é…ç½®æœ¬åœ°å­˜å‚¨ï¼‰

- **æ–‡ä»¶**: `graphgen/utils/help_nltk.py`
- **æ•°æ®**: 
  - `stopwords` (åœç”¨è¯)
  - `punkt_tab` (åˆ†è¯å™¨)
- **ä½ç½®**: `resources/nltk_data/`
- **çŠ¶æ€**: âœ… å·²é…ç½®ä¸ºæœ¬åœ°å­˜å‚¨
- **è¯´æ˜**: ä»£ç å·²è‡ªåŠ¨ä¸‹è½½åˆ°é¡¹ç›®æœ¬åœ°ç›®å½•

## ğŸ”§ HuggingFace æœ¬åœ°ç¼“å­˜é…ç½®

**âœ… å·²è‡ªåŠ¨é…ç½®**: ä»£ç å·²è‡ªåŠ¨é…ç½®ä¸ºä½¿ç”¨æœ¬åœ°ç¼“å­˜ç›®å½• `models/huggingface/`ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®ã€‚

### è‡ªåŠ¨é…ç½®è¯´æ˜

æ‰€æœ‰ä½¿ç”¨ HuggingFace æ¨¡å‹çš„ä»£ç å·²è‡ªåŠ¨é…ç½®ä¸ºï¼š
1. è‡ªåŠ¨åˆ›å»º `models/huggingface/` ç›®å½•
2. è‡ªåŠ¨è®¾ç½®ç¯å¢ƒå˜é‡ `TRANSFORMERS_CACHE` å’Œ `HF_HOME`
3. åœ¨ `from_pretrained()` è°ƒç”¨ä¸­æŒ‡å®š `cache_dir` å‚æ•°

### æ‰‹åŠ¨é…ç½®ï¼ˆå¯é€‰ï¼‰

å¦‚æœéœ€è¦è‡ªå®šä¹‰ç¼“å­˜ç›®å½•ï¼Œå¯ä»¥è®¾ç½®ç¯å¢ƒå˜é‡ï¼š

```bash
# Windows
set TRANSFORMERS_CACHE=D:\code\GraphGen\models\huggingface
set HF_HOME=D:\code\GraphGen\models\huggingface

# Linux/Mac
export TRANSFORMERS_CACHE=/path/to/GraphGen/models/huggingface
export HF_HOME=/path/to/GraphGen/models/huggingface
```

æˆ–è€…åœ¨ `.env` æ–‡ä»¶ä¸­ï¼š

```env
TRANSFORMERS_CACHE=./models/huggingface
HF_HOME=./models/huggingface
```

### ä½¿ç”¨é…ç½®è„šæœ¬

è¿è¡Œé…ç½®è„šæœ¬è‡ªåŠ¨è®¾ç½®æ‰€æœ‰ç¼“å­˜ç›®å½•ï¼š

```bash
python scripts/setup_model_cache.py
```

## ğŸ“¦ é¢„ä¸‹è½½æ¨¡å‹

### ä½¿ç”¨ HuggingFace CLI

```bash
# å®‰è£… huggingface-cli
pip install huggingface_hub

# ä¸‹è½½ Reward æ¨¡å‹
huggingface-cli download OpenAssistant/reward-model-deberta-v3-large-v2 --local-dir ./models/huggingface/OpenAssistant/reward-model-deberta-v3-large-v2

# ä¸‹è½½ UniEval æ¨¡å‹
huggingface-cli download MingZhong/unieval-sum --local-dir ./models/huggingface/MingZhong/unieval-sum
```

### ä½¿ç”¨ Python è„šæœ¬

```python
from huggingface_hub import snapshot_download

# ä¸‹è½½ Reward æ¨¡å‹
snapshot_download(
    repo_id="OpenAssistant/reward-model-deberta-v3-large-v2",
    local_dir="./models/huggingface/OpenAssistant/reward-model-deberta-v3-large-v2"
)

# ä¸‹è½½ UniEval æ¨¡å‹
snapshot_download(
    repo_id="MingZhong/unieval-sum",
    local_dir="./models/huggingface/MingZhong/unieval-sum"
)
```

## ğŸš€ è‡ªåŠ¨åŒ–é…ç½®è„šæœ¬

å¯ä»¥åˆ›å»ºä¸€ä¸ªåˆå§‹åŒ–è„šæœ¬æ¥é…ç½®æ‰€æœ‰æ¨¡å‹ç¼“å­˜ï¼š

```python
#!/usr/bin/env python3
"""é…ç½®æ‰€æœ‰æ¨¡å‹çš„æœ¬åœ°ç¼“å­˜ç›®å½•"""
import os
from pathlib import Path

PROJECT_ROOT = Path(__file__).parent

# åˆ›å»ºæ¨¡å‹ç›®å½•
model_dirs = [
    PROJECT_ROOT / "models" / "tokenizer",
    PROJECT_ROOT / "models" / "huggingface",
]

for dir_path in model_dirs:
    dir_path.mkdir(parents=True, exist_ok=True)
    print(f"âœ“ åˆ›å»ºç›®å½•: {dir_path}")

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["TRANSFORMERS_CACHE"] = str(PROJECT_ROOT / "models" / "huggingface")
os.environ["HF_HOME"] = str(PROJECT_ROOT / "models" / "huggingface")
os.environ["TIKTOKEN_CACHE_DIR"] = str(PROJECT_ROOT / "models" / "tokenizer")

print("\nâœ“ ç¯å¢ƒå˜é‡å·²è®¾ç½®")
print(f"  TRANSFORMERS_CACHE: {os.environ['TRANSFORMERS_CACHE']}")
print(f"  HF_HOME: {os.environ['HF_HOME']}")
print(f"  TIKTOKEN_CACHE_DIR: {os.environ['TIKTOKEN_CACHE_DIR']}")
```

## ğŸ“Š æ¨¡å‹ä½¿ç”¨æƒ…å†µ

### æ ¸å¿ƒåŠŸèƒ½ï¼ˆå¿…éœ€ï¼‰

- **Tiktoken (`cl100k_base`)**: âœ… å·²é…ç½®æœ¬åœ°å­˜å‚¨
  - ç”¨äºæ‰€æœ‰ token è®¡æ•°å’Œæ–‡æœ¬å¤„ç†
  - é»˜è®¤ tokenizer

### è¯„ä¼°åŠŸèƒ½ï¼ˆå¯é€‰ï¼‰

- **Reward Evaluator**: âš ï¸ éœ€è¦ç½‘ç»œä¸‹è½½
  - ä»…åœ¨è¿è¡Œ `graphgen/evaluate.py` æ—¶ä½¿ç”¨
  - å¦‚æœä¸éœ€è¦è¯„ä¼°åŠŸèƒ½ï¼Œå¯ä»¥å¿½ç•¥

- **UniEval**: âš ï¸ éœ€è¦ç½‘ç»œä¸‹è½½
  - ä»…åœ¨è¿è¡Œ `graphgen/evaluate.py` æ—¶ä½¿ç”¨
  - å¦‚æœä¸éœ€è¦è¯„ä¼°åŠŸèƒ½ï¼Œå¯ä»¥å¿½ç•¥

### å¤‡ç”¨ Tokenizerï¼ˆå¯é€‰ï¼‰

- **HuggingFace Tokenizer**: âš ï¸ éœ€è¦ç½‘ç»œä¸‹è½½
  - ä»…åœ¨ç”¨æˆ·æŒ‡å®šé tiktoken tokenizer æ—¶ä½¿ç”¨
  - é»˜è®¤ä½¿ç”¨ tiktokenï¼Œé€šå¸¸ä¸éœ€è¦

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **è¯„ä¼°æ¨¡å‹å¾ˆå¤§**: Reward å’Œ UniEval æ¨¡å‹æ¯ä¸ªçº¦ 1-2 GBï¼Œä¸‹è½½éœ€è¦æ—¶é—´
2. **é¦–æ¬¡ä½¿ç”¨**: é¦–æ¬¡ä½¿ç”¨æ—¶ä¼šè‡ªåŠ¨ä¸‹è½½ï¼Œéœ€è¦ç½‘ç»œè¿æ¥
3. **ç¦»çº¿ä½¿ç”¨**: å¦‚éœ€ç¦»çº¿ä½¿ç”¨ï¼Œè¯·é¢„å…ˆä¸‹è½½æ‰€æœ‰æ¨¡å‹
4. **ç£ç›˜ç©ºé—´**: ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´ï¼ˆè‡³å°‘ 5-10 GBï¼‰

## ğŸ” æ£€æŸ¥ç½‘ç»œä¾èµ–

è¿è¡Œä»¥ä¸‹å‘½ä»¤æ£€æŸ¥å“ªäº›æ¨¡å‹éœ€è¦ä¸‹è½½ï¼š

```python
import os
from pathlib import Path

# æ£€æŸ¥ tiktoken
tiktoken_dir = Path("models/tokenizer")
print(f"Tiktoken æ¨¡å‹ç›®å½•: {tiktoken_dir.exists()}")

# æ£€æŸ¥ HuggingFace
hf_dir = Path("models/huggingface")
print(f"HuggingFace ç¼“å­˜ç›®å½•: {hf_dir.exists()}")

# æ£€æŸ¥ NLTK
nltk_dir = Path("resources/nltk_data")
print(f"NLTK æ•°æ®ç›®å½•: {nltk_dir.exists()}")
```

## ğŸ“ æ€»ç»“

| æ¨¡å‹/æ•°æ® | çŠ¶æ€ | æœ¬åœ°å­˜å‚¨ | å¿…éœ€æ€§ |
|---------|------|---------|--------|
| Tiktoken (cl100k_base) | âœ… å·²é…ç½® | `models/tokenizer/` | å¿…éœ€ |
| NLTK æ•°æ® | âœ… å·²é…ç½® | `resources/nltk_data/` | å¿…éœ€ |
| HuggingFace Tokenizer | âœ… å·²é…ç½® | `models/huggingface/` | å¯é€‰ |
| Reward Evaluator | âœ… å·²é…ç½® | `models/huggingface/` | å¯é€‰ |
| UniEval | âœ… å·²é…ç½® | `models/huggingface/` | å¯é€‰ |

## âœ¨ æ›´æ–°è¯´æ˜

**2024-11-24**: æ‰€æœ‰æ¨¡å‹å·²é…ç½®ä¸ºè‡ªåŠ¨ä½¿ç”¨æœ¬åœ°å­˜å‚¨ç›®å½•ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®ã€‚ä»£ç ä¼šè‡ªåŠ¨ï¼š
- åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„
- è®¾ç½®ç¯å¢ƒå˜é‡
- åœ¨æ¨¡å‹åŠ è½½æ—¶æŒ‡å®šæœ¬åœ°ç¼“å­˜ç›®å½•

é¦–æ¬¡ä½¿ç”¨æ—¶ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½åˆ°æœ¬åœ°ç›®å½•ï¼Œä¹‹åå³å¯ç¦»çº¿ä½¿ç”¨ã€‚

