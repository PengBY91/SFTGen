#!/usr/bin/env python3
"""
æµ‹è¯•å¹¶è¡Œæ‰¹é‡å¤„ç†è„šæœ¬
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å¤šä¸ªæ¨¡å‹å¹¶è¡Œå¤„ç†ä»»åŠ¡
"""

import os
import sys
from pathlib import Path

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from batch_process_parallel import ParallelBatchProcessor, ModelConfig


def test_parallel_processing():
    """æµ‹è¯•å¹¶è¡Œæ‰¹é‡å¤„ç†"""
    print("=" * 80)
    print("æµ‹è¯•å¹¶è¡Œæ‰¹é‡å¤„ç† - å¤šæ¨¡å‹å¹¶è¡Œ")
    print("=" * 80)
    
    # é…ç½®å¤šä¸ªæ¨¡å‹
    model_configs = [
        ModelConfig(
            api_key=os.getenv("SYNTHESIZER_API_KEY", "sk-wFHN2ySjUYxCx3LrWAkJEMB11FMxYDvF6DHdye9yVDwIH2no"),
            synthesizer_url="https://api.huiyan-ai.cn/v1",
            synthesizer_model="gpt-4.1-mini-2025-04-14",
            model_id="model_1"
        ),
        ModelConfig(
            api_key=os.getenv("SYNTHESIZER_API_KEY", "sk-wFHN2ySjUYxCx3LrWAkJEMB11FMxYDvF6DHdye9yVDwIH2no"),
            synthesizer_url="https://api.huiyan-ai.cn/v1",
            synthesizer_model="gpt-4.1-mini-2025-04-14",
            model_id="model_2"
        ),
    ]
    
    # æµ‹è¯•æ–‡ä»¶åˆ—è¡¨
    test_files = [
        "test_data/sample_input.txt",
        # å¯ä»¥æ·»åŠ æ›´å¤šæµ‹è¯•æ–‡ä»¶
    ]
    
    # åˆ›å»ºå¹¶è¡Œå¤„ç†å™¨
    processor = ParallelBatchProcessor(
        model_configs=model_configs,
        output_dir="test_data/parallel_outputs",
        log_dir="test_data/parallel_logs",
        batch_size=2,  # æ¯ä¸ªæ¨¡å‹åŒæ—¶å¤„ç† 2 ä¸ªä»»åŠ¡
        max_workers=4,  # æ€»å…± 4 ä¸ªå·¥ä½œçº¿ç¨‹
        output_data_type="all",  # ä½¿ç”¨ "all" æ¨¡å¼
        output_data_format="Alpaca",
    )
    
    print(f"\nğŸ“Š é…ç½®ä¿¡æ¯:")
    print(f"   æ¨¡å‹æ•°é‡: {len(model_configs)}")
    print(f"   Batch size: 2")
    print(f"   æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°: 4")
    print(f"   æµ‹è¯•æ–‡ä»¶æ•°: {len(test_files)}")
    print(f"   ç”Ÿæˆæ¨¡å¼: all")
    
    # å¤„ç†æ–‡ä»¶
    print("\nğŸš€ å¼€å§‹å¹¶è¡Œå¤„ç†...")
    result = processor.process_batch(test_files)
    
    # æ˜¾ç¤ºç»“æœ
    print("\n" + "=" * 80)
    print("å¤„ç†ç»“æœ")
    print("=" * 80)
    
    if result["success"]:
        print("âœ… æ‰€æœ‰æ–‡ä»¶å¤„ç†æˆåŠŸ!")
    else:
        print(f"âš ï¸  æœ‰ {result['stats']['failed_files']} ä¸ªæ–‡ä»¶å¤„ç†å¤±è´¥")
    
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   æ€»æ–‡ä»¶æ•°: {result['stats']['total_files']}")
    print(f"   æˆåŠŸå¤„ç†: {result['stats']['processed_files']}")
    print(f"   å¤„ç†å¤±è´¥: {result['stats']['failed_files']}")
    print(f"   æ€» Token ä½¿ç”¨é‡: {result['stats']['total_tokens']:,}")
    print(f"   æ€»å¤„ç†æ—¶é—´: {result['stats']['total_time']:.2f}ç§’")
    
    # å„æ¨¡å‹ç»Ÿè®¡
    print(f"\nğŸ“ˆ å„æ¨¡å‹å¤„ç†ç»Ÿè®¡:")
    for model_id, model_stat in result['stats']['model_stats'].items():
        print(f"   {model_id}:")
        print(f"     æˆåŠŸ: {model_stat['processed']}")
        print(f"     å¤±è´¥: {model_stat['failed']}")
        print(f"     Tokens: {model_stat['tokens']:,}")
    
    # ä¿å­˜ç»“æœ
    processor.save_results()
    
    return result["success"]


if __name__ == "__main__":
    try:
        success = test_parallel_processing()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­äº†å¤„ç†è¿‡ç¨‹")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

